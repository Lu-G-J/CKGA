{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "from openke.config import Trainer, Tester\n",
    "from openke.data import TrainDataLoader, TestDataLoader\n",
    "from openke.data.PyTorchTrainDataLoader import PyTorchTrainDataLoader\n",
    "from openke.module.model import TransE, TransH, TransR, RotatE\n",
    "from openke.module.strategy import NegativeSampling\n",
    "from openke.module.loss import MarginLoss, SigmoidLoss\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "def get_parser(jupyter=False):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', type=str, default='laptop')\n",
    "    parser.add_argument('--nbatches', type=int, default=100)\n",
    "    parser.add_argument('--threads', type=int, default=16)\n",
    "    parser.add_argument('--sampling_model', type=str, default='normal')\n",
    "    parser.add_argument('--bern_flag', type=int, default=1)\n",
    "    parser.add_argument('--filter_flag', type=int, default=1)\n",
    "    parser.add_argument('--neg_ent', type=int, default=25)\n",
    "    parser.add_argument('--neg_rel', type=int, default=0)\n",
    "    parser.add_argument('--emb_dim', type=int, default=200)\n",
    "    parser.add_argument('--p_norm', type=int, default=1)\n",
    "    parser.add_argument('--norm_flag', type=str2bool, default='True')\n",
    "    parser.add_argument('--margin', type=float, default=5.0)\n",
    "    parser.add_argument('--train_epoch', type=int, default=10)\n",
    "    parser.add_argument('--alpha', type=float, default=1.0)\n",
    "    parser.add_argument('--use_gpu', type=str2bool, default='True')\n",
    "    \n",
    "    if jupyter is True : args = parser.parse_args(args=[])\n",
    "    else : args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 | loss: 3.645945: 100%|██████████| 10/10 [00:02<00:00,  3.94it/s]\n",
      "100%|██████████| 12741/12741 [00:16<00:00, 770.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9043246507644653\n",
      "mrr: 0.8357038497924805, mr: 128.99847412109375, hit10: 0.9043246507644653, hit3: 0.8641393780708313, hit1: 0.7953850030899048\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = TrainDataLoader(\n",
    "    in_path = f'./benchmarks/{args.dataset}/', # if not correct, it will failed without log\n",
    "    nbatches = args.nbatches,\n",
    "    threads = args.threads, \n",
    "    sampling_mode = args.sampling_model, \n",
    "    bern_flag = args.bern_flag, \n",
    "    filter_flag = args.filter_flag, \n",
    "    neg_ent = args.neg_ent,\n",
    "    neg_rel = args.neg_rel)\n",
    "\n",
    "test_dataloader = TestDataLoader(f'./benchmarks/{args.dataset}/', \"link\",type_constrain=False)\n",
    "\n",
    "transe = TransE(\n",
    "    ent_tot = train_dataloader.get_ent_tot(),\n",
    "    rel_tot = train_dataloader.get_rel_tot(),\n",
    "    dim = args.emb_dim,\n",
    "    p_norm = args.p_norm,\n",
    "    norm_flag = args.norm_flag)\n",
    "\n",
    "model = NegativeSampling(\n",
    "    model = transe,\n",
    "    loss = MarginLoss(margin=args.margin),\n",
    "    batch_size = train_dataloader.get_batch_size())\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model, \n",
    "    data_loader = train_dataloader, \n",
    "    train_times = args.train_epoch, \n",
    "    alpha = args.alpha,\n",
    "    use_gpu = args.use_gpu)\n",
    "\n",
    "trainer.run()\n",
    "\n",
    "tester = Tester(\n",
    "    model = transe, \n",
    "    data_loader = test_dataloader, \n",
    "    use_gpu = args.use_gpu)\n",
    "\n",
    "mrr, mr, hit10, hit3, hit1 = tester.run_link_prediction(type_constrain = False)\n",
    "print(f\"mrr: {mrr}, mr: {mr}, hit10: {hit10}, hit3: {hit3}, hit1: {hit1}\")\n",
    "\n",
    "output = transe.ent_embeddings.weight.cpu().detach().numpy()\n",
    "pickle.dump(output, open(f'./graph/{args.dataset}_kge_transe.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the arg\n",
    "args = get_parser(jupyter=True)\n",
    "args.dataset = 'laptop'\n",
    "args.train_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 | loss: 3.789272: 100%|██████████| 10/10 [00:18<00:00,  1.85s/it]\n",
      "100%|██████████| 12741/12741 [01:10<00:00, 180.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9054626822471619\n",
      "mrr: 0.8374, mr: 123.2658, hit10: 0.9055, hit3: 0.8622, hit1: 0.7986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = TrainDataLoader(\n",
    "    in_path = f'./benchmarks/{args.dataset}/', # if not correct, it will failed without log\n",
    "    nbatches = args.nbatches,\n",
    "    threads = args.threads, \n",
    "    sampling_mode = args.sampling_model, \n",
    "    bern_flag = args.bern_flag, \n",
    "    filter_flag = args.filter_flag, \n",
    "    neg_ent = args.neg_ent,\n",
    "    neg_rel = args.neg_rel)\n",
    "\n",
    "test_dataloader = TestDataLoader(f'./benchmarks/{args.dataset}/', \"link\",type_constrain=False)\n",
    "\n",
    "transh = TransH(\n",
    "    ent_tot = train_dataloader.get_ent_tot(),\n",
    "    rel_tot = train_dataloader.get_rel_tot(),\n",
    "    dim = args.emb_dim,\n",
    "    p_norm = args.p_norm,\n",
    "    norm_flag = args.norm_flag)\n",
    "\n",
    "model = NegativeSampling(\n",
    "\tmodel = transh, \n",
    "\tloss = MarginLoss(margin = args.margin),\n",
    "\tbatch_size = train_dataloader.get_batch_size()\n",
    ")\n",
    "\n",
    "# train the model\n",
    "trainer = Trainer(\n",
    "    model = model, \n",
    "    data_loader = train_dataloader, \n",
    "    train_times = args.train_epoch, \n",
    "    alpha = args.alpha,\n",
    "    use_gpu = args.use_gpu)\n",
    "\n",
    "trainer.run()\n",
    "\n",
    "tester = Tester(\n",
    "    model = transh, \n",
    "    data_loader = test_dataloader, \n",
    "    use_gpu = args.use_gpu)\n",
    "\n",
    "mrr, mr, hit10, hit3, hit1 = tester.run_link_prediction(type_constrain = False)\n",
    "print(f\"mrr: {'%.4f'%mrr}, mr: {'%.4f'%mr}, hit10: {'%.4f'%hit10}, hit3: {'%.4f'%hit3}, hit1: {'%.4f'%hit1}\")\n",
    "\n",
    "\n",
    "output = transh.ent_embeddings.weight.cpu().detach().numpy()\n",
    "pickle.dump(output, open(f'./graph/{args.dataset}_kge_transh.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the arg\n",
    "args = get_parser(jupyter=True)\n",
    "args.dataset = 'twitter'\n",
    "args.train_epoch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | loss: 24.854141: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 | loss: 0.407803: 100%|██████████| 25/25 [01:46<00:00,  4.25s/it]\n",
      "100%|██████████| 13313/13313 [01:16<00:00, 173.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937091588973999\n",
      "mrr: 0.8746, mr: 23.1594, hit10: 0.9371, hit3: 0.9087, hit1: 0.8330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = TrainDataLoader(\n",
    "    in_path = f'./benchmarks/{args.dataset}/', # if not correct, it will failed without log\n",
    "    nbatches = args.nbatches,\n",
    "    threads = args.threads, \n",
    "    sampling_mode = args.sampling_model, \n",
    "    bern_flag = args.bern_flag, \n",
    "    filter_flag = args.filter_flag, \n",
    "    neg_ent = args.neg_ent,\n",
    "    neg_rel = args.neg_rel)\n",
    "\n",
    "test_dataloader = TestDataLoader(f'./benchmarks/{args.dataset}/', \"link\",type_constrain=False)\n",
    "\n",
    "transe = TransE(\n",
    "    ent_tot = train_dataloader.get_ent_tot(),\n",
    "    rel_tot = train_dataloader.get_rel_tot(),\n",
    "    dim = args.emb_dim,\n",
    "    p_norm = args.p_norm,\n",
    "    norm_flag = args.norm_flag)\n",
    "\n",
    "model_e = NegativeSampling(\n",
    "    model = transe,\n",
    "    loss = MarginLoss(margin=args.margin),\n",
    "    batch_size = train_dataloader.get_batch_size())\n",
    "\n",
    "transr = TransR(\n",
    "\tent_tot = train_dataloader.get_ent_tot(),\n",
    "\trel_tot = train_dataloader.get_rel_tot(),\n",
    "\tdim_e = args.emb_dim,\n",
    "\tdim_r = args.emb_dim,\n",
    "\tp_norm = args.p_norm, \n",
    "\tnorm_flag = args.norm_flag,\n",
    "\trand_init = False)\n",
    "\n",
    "model_r = NegativeSampling(\n",
    "\tmodel = transr,\n",
    "\tloss = MarginLoss(margin = args.margin-1),\n",
    "\tbatch_size = train_dataloader.get_batch_size()\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model_e, \n",
    "    data_loader = train_dataloader, \n",
    "    train_times = 1, \n",
    "    alpha = 0.5,\n",
    "    use_gpu = args.use_gpu)\n",
    "trainer.run()\n",
    "parameters = transe.get_parameters()\n",
    "\n",
    "transr.set_parameters(parameters)\n",
    "trainer = Trainer(\n",
    "    model = model_r, \n",
    "    data_loader = train_dataloader, \n",
    "    train_times = args.train_epoch, \n",
    "    alpha = args.alpha, \n",
    "    use_gpu = args.use_gpu)\n",
    "\n",
    "trainer.run()\n",
    "tester = Tester(\n",
    "    model = transr, \n",
    "    data_loader = test_dataloader, \n",
    "    use_gpu = args.use_gpu)\n",
    "\n",
    "mrr, mr, hit10, hit3, hit1 = tester.run_link_prediction(type_constrain = False)\n",
    "print(f\"mrr: {'%.4f'%mrr}, mr: {'%.4f'%mr}, hit10: {'%.4f'%hit10}, hit3: {'%.4f'%hit3}, hit1: {'%.4f'%hit1}\")\n",
    "\n",
    "output = transr.ent_embeddings.weight.cpu().detach().numpy()\n",
    "pickle.dump(output, open(f'./graph/{args.dataset}_kge_transr.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RotatE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_parser(jupyter=True)\n",
    "args.dataset = 'laptop'\n",
    "args.sampling_mode = 'cross'\n",
    "args.batch_size = 2000\n",
    "args.thread = 8\n",
    "args.bern_flag = 0\n",
    "args.filter_flag = 1\n",
    "args.neg_ent = 64\n",
    "args.neg_rel = 0\n",
    "args.emb_dim = 200\n",
    "args.train_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader for training\n",
    "train_dataloader = TrainDataLoader(\n",
    "\tin_path = f\"./benchmarks/{args.dataset}/\", \n",
    "\tbatch_size = args.batch_size,\n",
    "\tthreads = args.thread,\n",
    "\tsampling_mode = \"cross\", \n",
    "\tbern_flag = args.bern_flag, \n",
    "\tfilter_flag = args.filter_flag, \n",
    "\tneg_ent = args.neg_ent,\n",
    "\tneg_rel = args.neg_rel\n",
    ")\n",
    "\n",
    "# dataloader for test\n",
    "test_dataloader = TestDataLoader(f\"./benchmarks/{args.dataset}/\", \"link\",type_constrain=False)\n",
    "\n",
    "# define the model\n",
    "rotate = RotatE(\n",
    "\tent_tot = train_dataloader.get_ent_tot(),\n",
    "\trel_tot = train_dataloader.get_rel_tot(),\n",
    "\tdim = args.emb_dim,\n",
    "\tmargin = 6.0,\n",
    "\tepsilon = 2.0,\n",
    ")\n",
    "\n",
    "# define the loss function\n",
    "model = NegativeSampling(\n",
    "\tmodel = rotate, \n",
    "\tloss = SigmoidLoss(adv_temperature = 2),\n",
    "\tbatch_size = train_dataloader.get_batch_size(), \n",
    "\tregul_rate = 0.0\n",
    ")\n",
    "\n",
    "# train the model\n",
    "trainer = Trainer(model = model, data_loader = train_dataloader, train_times = args.train_epoch, alpha = 2e-5, use_gpu = args.use_gpu, opt_method = \"adam\")\n",
    "trainer.run()\n",
    "\n",
    "tester = Tester(model = rotate, data_loader = test_dataloader, use_gpu = True)\n",
    "\n",
    "mrr, mr, hit10, hit3, hit1 = tester.run_link_prediction(type_constrain = False)\n",
    "print(f\"mrr: {'%.4f'%mrr}, mr: {'%.4f'%mr}, hit10: {'%.4f'%hit10}, hit3: {'%.4f'%hit3}, hit1: {'%.4f'%hit1}\")\n",
    "\n",
    "output = rotate.ent_embeddings.weight.cpu().detach().numpy()\n",
    "pickle.dump(output, open(f'./graph/{args.dataset}_kge_rotate_1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d931657f8858ac28e9aaed952a72b6ee33c80e6eba26d255eafd4a93893c915"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
